{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47d5b45",
   "metadata": {},
   "source": [
    "# Лабораторная работа №7: Исследования с моделями семантической сегментации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3561287d",
   "metadata": {},
   "source": [
    "## 1. Выбор начальных условий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa07e81",
   "metadata": {},
   "source": [
    "### Набор данных\n",
    "\n",
    "Camvid dataset\n",
    "\n",
    "Задача: сегментация дорожных сцен "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50599e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (1.7.4.2)\n",
      "Requirement already satisfied: bleach in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (3.7)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (6.30.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (75.8.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "295741c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/naureenmohammad/camvid-dataset\n",
      "License(s): unknown\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d naureenmohammad/camvid-dataset -p data --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f3d5bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.0.8)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pycocotools) (3.8.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pycocotools) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/arsyarullin/Library/Python/3.11/lib/python/site-packages (from matplotlib>=2.1.0->pycocotools) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/arsyarullin/Library/Python/3.11/lib/python/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/arsyarullin/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: segmentation_models_pytorch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from segmentation_models_pytorch) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from segmentation_models_pytorch) (1.26.4)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from segmentation_models_pytorch) (10.3.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from segmentation_models_pytorch) (0.5.3)\n",
      "Requirement already satisfied: timm>=0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from segmentation_models_pytorch) (1.0.15)\n",
      "Requirement already satisfied: torch>=1.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from segmentation_models_pytorch) (2.7.0)\n",
      "Requirement already satisfied: torchvision>=0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from segmentation_models_pytorch) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from segmentation_models_pytorch) (4.66.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/arsyarullin/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (6.0.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/arsyarullin/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (4.11.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (1.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.8->segmentation_models_pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.8->segmentation_models_pytorch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting albumentations\n",
      "  Using cached albumentations-2.0.6-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from albumentations) (1.13.0)\n",
      "Requirement already satisfied: PyYAML in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from albumentations) (6.0.2)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
      "  Downloading stringzilla-3.12.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (80 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
      "  Downloading simsimd-6.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (66 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading albumentations-2.0.6-py3-none-any.whl (332 kB)\n",
      "Downloading albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading simsimd-6.2.1-cp311-cp311-macosx_11_0_arm64.whl (93 kB)\n",
      "Downloading stringzilla-3.12.5-cp311-cp311-macosx_11_0_arm64.whl (79 kB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: stringzilla, simsimd, typing-extensions, opencv-python-headless, annotated-types, typing-inspection, pydantic-core, albucore, pydantic, albumentations\n",
      "\u001b[2K  Attempting uninstall: typing-extensions\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.11.0\n",
      "\u001b[2K    Uninstalling typing_extensions-4.11.0:\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.11.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [albumentations]m [albumentations]eadless]\n",
      "\u001b[1A\u001b[2KSuccessfully installed albucore-0.0.24 albumentations-2.0.6 annotated-types-0.7.0 opencv-python-headless-4.11.0.86 pydantic-2.11.4 pydantic-core-2.33.2 simsimd-6.2.1 stringzilla-3.12.5 typing-extensions-4.13.2 typing-inspection-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pycocotools\n",
    "%pip install segmentation_models_pytorch\n",
    "%pip install opencv-python\n",
    "%pip install --upgrade albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cefbc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0a6e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CamVidDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        super().__init__()\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir  = masks_dir\n",
    "        self.images = sorted(os.listdir(images_dir))\n",
    "        self.masks  = sorted(os.listdir(masks_dir))\n",
    "        assert len(self.images) == len(self.masks), \\\n",
    "            \"Число изображений и масок должно совпадать\"\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path  = os.path.join(self.images_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.masks_dir,  self.masks[idx])\n",
    "        image = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        mask  = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image, mask = augmented['image'], augmented['mask']\n",
    "\n",
    "        return image, mask.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d485bd5",
   "metadata": {},
   "source": [
    "### Выбор метрики\n",
    "\n",
    "В качестве метрики качества будем использовать F1 score (и дополнительно IoU) - стандартные метрики для задач подобного типа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f53da",
   "metadata": {},
   "source": [
    "## 2. Создание бейзлайна и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00127e4f",
   "metadata": {},
   "source": [
    "### Обучение сверточной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45bb61c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.22.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f91d2b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.metrics.functional import get_stats, iou_score, f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Dict\n",
    "\n",
    "def evaluate_segmentation(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device,\n",
    "    num_classes: int\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    dice_criterion = smp.losses.DiceLoss(mode='multiclass')\n",
    "    ce_criterion   = nn.CrossEntropyLoss()\n",
    "\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_iou  = 0.0\n",
    "    cumulative_f1   = 0.0\n",
    "    batch_count     = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(device)\n",
    "            masks  = masks.to(device)\n",
    "\n",
    "            logits = model(images)\n",
    "            loss   = dice_criterion(logits, masks) + ce_criterion(logits, masks)\n",
    "            cumulative_loss += loss.item()\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            tp, fp, fn, tn = get_stats(\n",
    "                preds, masks,\n",
    "                mode='multiclass',\n",
    "                num_classes=num_classes\n",
    "            )\n",
    "            cumulative_iou += iou_score(tp, fp, fn, tn, reduction='micro').item()\n",
    "            cumulative_f1  += f1_score(tp, fp, fn, tn, reduction='micro').item()\n",
    "\n",
    "            batch_count += 1\n",
    "\n",
    "    avg_loss   = cumulative_loss / batch_count\n",
    "    avg_iou    = cumulative_iou  / batch_count\n",
    "    avg_f1     = cumulative_f1   / batch_count\n",
    "\n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'iou':  avg_iou,\n",
    "        'f1_score': avg_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7061438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "def train_and_validate(\n",
    "    model: nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader: torch.utils.data.DataLoader,\n",
    "    num_epochs: int,\n",
    "    learning_rate: float = 1e-3,\n",
    "    device: torch.device = torch.device('cpu')\n",
    ") -> None:\n",
    "    model.to(device)\n",
    "\n",
    "    dice_loss_fn = smp.losses.DiceLoss(mode='multiclass')\n",
    "    ce_loss_fn   = nn.CrossEntropyLoss()\n",
    "    optimizer    = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        for images, masks in tqdm(train_loader, desc=f\"Train Epoch {epoch}\", leave=False):\n",
    "            images = images.to(device)\n",
    "            masks  = masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(images)\n",
    "            loss   = dice_loss_fn(logits, masks) + ce_loss_fn(logits, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        metrics = evaluate_segmentation(\n",
    "            model, val_loader, device, num_classes=model.num_classes if hasattr(model, 'num_classes') else masks.max().item()+1\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{num_epochs} | \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "            f\"Val Loss: {metrics['loss']:.4f} | \"\n",
    "            f\"IoU: {metrics['iou']:.4f} | \"\n",
    "            f\"F1: {metrics['f1_score']:.4f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ecfbcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 367\n",
      "Val   samples: 101\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomCrop(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_ds = CamVidDataset(\n",
    "    images_dir=\"data/train\",\n",
    "    masks_dir =\"data/trainannot\",\n",
    "    transform=train_transform\n",
    ")\n",
    "val_ds = CamVidDataset(\n",
    "    images_dir=\"data/val\",\n",
    "    masks_dir =\"data/valannot\",\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_ds)}\")\n",
    "print(f\"Val   samples: {len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5ecbc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 3.1451 | Val Loss: 9.8100 | IoU: 0.0326 | F1: 0.0631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Train Loss: 1.9568 | Val Loss: 1.5185 | IoU: 0.6539 | F1: 0.7906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Train Loss: 1.2732 | Val Loss: 1.2162 | IoU: 0.6490 | F1: 0.7870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Train Loss: 0.9889 | Val Loss: 0.9939 | IoU: 0.6542 | F1: 0.7908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Train Loss: 0.8551 | Val Loss: 0.9008 | IoU: 0.7228 | F1: 0.8385\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 32\n",
    "model_unet = smp.Unet(\n",
    "   encoder_name=\"resnet18\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    classes=NUM_CLASSES\n",
    ").to(device)\n",
    "\n",
    "train_and_validate(model_unet, train_loader, val_loader, num_epochs=5, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2419e4",
   "metadata": {},
   "source": [
    "### Оценка качества сверточной модели\n",
    "\n",
    "Получаем хороший результат = 0.8385"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f651d0",
   "metadata": {},
   "source": [
    "### Обучение трансформерной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6cf6db96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1:   0%|          | 0/12 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 1.7280 | Val Loss: 1.1746 | IoU: 0.6308 | F1: 0.7733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 | Train Loss: 0.8911 | Val Loss: 0.7963 | IoU: 0.7098 | F1: 0.8296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 | Train Loss: 0.7724 | Val Loss: 0.7107 | IoU: 0.7208 | F1: 0.8372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 | Train Loss: 0.6837 | Val Loss: 0.7111 | IoU: 0.7087 | F1: 0.8288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 | Train Loss: 0.6184 | Val Loss: 0.5679 | IoU: 0.7746 | F1: 0.8725\n"
     ]
    }
   ],
   "source": [
    "model_segformer = smp.Segformer(\n",
    "    encoder_name=\"mit_b0\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=NUM_CLASSES,\n",
    "    activation=None\n",
    ").to(device)\n",
    "\n",
    "train_and_validate(model_segformer, train_loader, val_loader, num_epochs=5, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d6b71",
   "metadata": {},
   "source": [
    "### Оценка качества трансформерной модели\n",
    "\n",
    "Получаем хороший результат = 0.8725"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70926e9f",
   "metadata": {},
   "source": [
    "## 3. Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3b945",
   "metadata": {},
   "source": [
    "### Гипотеза\n",
    "\n",
    "Добавление цветовых искажений, случайных поворотов и обрезок — увеличат разнообразие обучающих примеров и улучшат обобщающую способность модели. Переход на оптимизатор AdamW в связке с планировщиком скорости обучения (scheduler) обеспечит более стабилизированную и адаптивную динамику обновления весов, что поможет избежать переобучения. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadcbbb2",
   "metadata": {},
   "source": [
    "### Обучение сверточной модели с использованием гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97fc6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "improv_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ColorJitter(p=0.5),\n",
    "    A.RandomCrop(224, 224),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "model_unet = smp.Unet(\n",
    "   encoder_name=\"resnet18\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    classes=NUM_CLASSES\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model_unet.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "ce_loss   = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def train_and_validate(\n",
    "    model: nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader:   torch.utils.data.DataLoader,\n",
    "    num_epochs:   int,\n",
    "    optimizer,\n",
    "    scheduler:    Optional[optim.lr_scheduler._LRScheduler] = None,\n",
    "    device:       torch.device = torch.device('cpu')\n",
    ") -> None:\n",
    "    model.to(device)\n",
    "\n",
    "    dice_loss_fn = smp.losses.DiceLoss(mode='multiclass')\n",
    "    ce_loss_fn   = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"\\nEpoch {epoch}/{num_epochs} — LR: {current_lr:.2e}\")\n",
    "\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        for images, masks in tqdm(train_loader, desc=\"  Train\", leave=False):\n",
    "            images = images.to(device)\n",
    "            masks  = masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(images)\n",
    "            loss   = dice_loss_fn(logits, masks) + ce_loss_fn(logits, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        metrics = evaluate_segmentation(\n",
    "            model,\n",
    "            val_loader,\n",
    "            device,\n",
    "            num_classes=getattr(model, 'num_classes', masks.max().item() + 1)\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"  Train Loss: {avg_train_loss:.4f}  \"\n",
    "            f\"| Val Loss: {metrics['loss']:.4f}  \"\n",
    "            f\"| IoU: {metrics['iou']:.4f}  \"\n",
    "            f\"| F1: {metrics['f1_score']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(metrics['loss'])\n",
    "            else:\n",
    "                scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "463f5080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Train:   0%|          | 0/12 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.8596  | Val Loss: 1.0574  | IoU: 0.6430  | F1: 0.7823\n",
      "\n",
      "Epoch 2/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.7541  | Val Loss: 0.7783  | IoU: 0.7381  | F1: 0.8485\n",
      "\n",
      "Epoch 3/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.6973  | Val Loss: 0.8140  | IoU: 0.7183  | F1: 0.8356\n",
      "\n",
      "Epoch 4/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.6849  | Val Loss: 0.7010  | IoU: 0.7421  | F1: 0.8511\n",
      "\n",
      "Epoch 5/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.6637  | Val Loss: 0.8330  | IoU: 0.7115  | F1: 0.8294\n"
     ]
    }
   ],
   "source": [
    "train_and_validate(model_unet, train_loader, val_loader, num_epochs=5, learning_rate=1e-3, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f013a",
   "metadata": {},
   "source": [
    "### Оценка качества улучшенной сверточной модели\n",
    "\n",
    "Получаем F1 = 0.8294, гипотезы не улучшили бейзлайн модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3889a55",
   "metadata": {},
   "source": [
    "### Обучение трансформерной модели с использованием гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_segformer = smp.Segformer(\n",
    "    encoder_name=\"mit_b0\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=NUM_CLASSES,\n",
    "    activation=None\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model_unet.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "ce_loss   = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Train:   0%|          | 0/12 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.7447  | Val Loss: 0.5606  | IoU: 0.7748  | F1: 0.8728\n",
      "\n",
      "Epoch 2/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.6014  | Val Loss: 0.5525  | IoU: 0.7748  | F1: 0.8727\n",
      "\n",
      "Epoch 3/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5436  | Val Loss: 0.5150  | IoU: 0.7904  | F1: 0.8828\n",
      "\n",
      "Epoch 4/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.5140  | Val Loss: 0.5006  | IoU: 0.7952  | F1: 0.8856\n",
      "\n",
      "Epoch 5/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 0.4887  | Val Loss: 0.4862  | IoU: 0.8035  | F1: 0.8907\n"
     ]
    }
   ],
   "source": [
    "train_and_validate(model_segformer, train_loader, val_loader, num_epochs=5, optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da717d3",
   "metadata": {},
   "source": [
    "### Оценка качества улучшенной трансформерной модели\n",
    "\n",
    "Получаем F1 = 0.8907, что лучше базовой модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1860e3fd",
   "metadata": {},
   "source": [
    "## 4. Имплементация алгоритма машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef1845",
   "metadata": {},
   "source": [
    "### Самостоятельная имплементация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb512724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm import tqdm\n",
    "from segmentation_models_pytorch.metrics.functional import get_stats, iou_score, f1_score\n",
    "\n",
    "\n",
    "class DoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class CustomUNet(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.down1 = DoubleConvBlock(3, 64)\n",
    "        self.down2 = DoubleConvBlock(64, 128)\n",
    "        self.down3 = DoubleConvBlock(128, 256)\n",
    "        self.bottleneck = DoubleConvBlock(256, 512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.up3  = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.up2  = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.up1  = nn.ConvTranspose2d(128,  64, kernel_size=2, stride=2)\n",
    "\n",
    "        self.upconv3 = DoubleConvBlock(512, 256)\n",
    "        self.upconv2 = DoubleConvBlock(256, 128)\n",
    "        self.upconv1 = DoubleConvBlock(128,  64)\n",
    "\n",
    "        self.classifier = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(self.pool(x1))\n",
    "        x3 = self.down3(self.pool(x2))\n",
    "        x4 = self.bottleneck(self.pool(x3))\n",
    "\n",
    "        u3 = self.upconv3(torch.cat([self.up3(x4), x3], dim=1))\n",
    "        u2 = self.upconv2(torch.cat([self.up2(u3), x2], dim=1))\n",
    "        u1 = self.upconv1(torch.cat([self.up1(u2), x1], dim=1))\n",
    "\n",
    "        return self.classifier(u1)\n",
    "\n",
    "class CustomSegmentationTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_size: int = 224,\n",
    "        patch_size: int = 32,\n",
    "        in_channels: int = 3,\n",
    "        embed_dim: int = 128,\n",
    "        num_heads: int = 4,\n",
    "        num_layers: int = 2,\n",
    "        num_classes: int = 32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        num_patches = (img_size // patch_size) ** 2\n",
    "\n",
    "        self.patch_embed = nn.Conv2d(\n",
    "            in_channels, embed_dim,\n",
    "            kernel_size=patch_size, stride=patch_size\n",
    "        )\n",
    "        self.positional_embedding = nn.Parameter(\n",
    "            torch.zeros(1, num_patches, embed_dim)\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=embed_dim * 2,\n",
    "            dropout=0.1,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(embed_dim, embed_dim,\n",
    "                               kernel_size=patch_size,\n",
    "                               stride=patch_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(embed_dim, embed_dim // 2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(embed_dim // 2, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.patch_embed(x)\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        x = x.flatten(2).transpose(1, 2) + self.positional_embedding\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.transpose(1, 2).view(B, C, H, W)\n",
    "\n",
    "        return self.decoder(x)\n",
    "\n",
    "\n",
    "def evaluate_custom(\n",
    "    model: nn.Module,\n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    "    num_classes: int\n",
    ") -> dict[str, float]:\n",
    "    model.eval()\n",
    "    dice_fn = smp.losses.DiceLoss(mode='multiclass')\n",
    "    ce_fn   = nn.CrossEntropyLoss()\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    sum_iou  = 0.0\n",
    "    sum_f1   = 0.0\n",
    "    count    = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in loader:\n",
    "            inputs  = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            logits = model(inputs)\n",
    "            loss   = dice_fn(logits, targets) + ce_fn(logits, targets)\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "            preds = logits.argmax(dim=1)\n",
    "            tp, fp, fn, tn = get_stats(\n",
    "                preds, targets,\n",
    "                mode='multiclass',\n",
    "                num_classes=num_classes\n",
    "            )\n",
    "            sum_iou += iou_score(tp, fp, fn, tn, reduction='micro').item()\n",
    "            sum_f1  += f1_score(tp, fp, fn, tn, reduction='micro').item()\n",
    "            count  += 1\n",
    "\n",
    "    return {\n",
    "        'loss': sum_loss / count,\n",
    "        'iou':  sum_iou  / count,\n",
    "        'f1':   sum_f1   / count\n",
    "    }\n",
    "\n",
    "def train_custom_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader:   torch.utils.data.DataLoader,\n",
    "    num_epochs:   int,\n",
    "    learning_rate: float                 = 1e-3,\n",
    "    scheduler:    Optional[optim.lr_scheduler._LRScheduler] = None,\n",
    "    device:       torch.device            = torch.device('cpu')\n",
    ") -> None:\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    dice_loss_fn = smp.losses.DiceLoss(mode='multiclass')\n",
    "    ce_loss_fn   = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"\\nEpoch {epoch}/{num_epochs} — LR: {current_lr:.2e}\")\n",
    "\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        for inputs, targets in tqdm(train_loader, desc=\"  Train\", leave=False):\n",
    "            inputs  = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(inputs)\n",
    "            loss   = dice_loss_fn(logits, targets) + ce_loss_fn(logits, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        metrics = evaluate_custom(\n",
    "            model, val_loader, device,\n",
    "            num_classes=getattr(model.classifier, 'out_channels', targets.max().item()+1)\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"  Train Loss: {avg_train_loss:.4f}  \"\n",
    "            f\"| Val Loss: {metrics['loss']:.4f}  \"\n",
    "            f\"| IoU: {metrics['iou']:.4f}  \"\n",
    "            f\"| F1: {metrics['f1']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(metrics['loss'])\n",
    "            else:\n",
    "                scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd76ba2",
   "metadata": {},
   "source": [
    "### Обучение самостоятельной сверточной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "479a34c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Train:   0%|          | 0/12 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.6430  | Val Loss: 2.9532  | IoU: 0.1015  | F1: 0.1842\n",
      "\n",
      "Epoch 2/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 2.5770  | Val Loss: 2.2999  | IoU: 0.2084  | F1: 0.3439\n",
      "\n",
      "Epoch 3/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 2.1316  | Val Loss: 2.1289  | IoU: 0.3056  | F1: 0.4671\n",
      "\n",
      "Epoch 4/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 2.0523  | Val Loss: 2.0926  | IoU: 0.2079  | F1: 0.3432\n",
      "\n",
      "Epoch 5/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.9555  | Val Loss: 2.0175  | IoU: 0.2515  | F1: 0.4013\n"
     ]
    }
   ],
   "source": [
    "unet_custom = CustomUNet(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "train_and_validate(unet_custom, train_loader, val_loader, num_epochs=5, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a9cb68",
   "metadata": {},
   "source": [
    "### Оценка качества самостоятельной сверточной модели\n",
    "\n",
    "Получаем accuracy = 0.4013, что довольно неплохо, но ощутимо ниже готовой модели "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ed6ad",
   "metadata": {},
   "source": [
    "### Обучение самостоятельной сверточной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d514e9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Train:   0%|          | 0/12 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 3.0350  | Val Loss: 2.2780  | IoU: 0.1961  | F1: 0.3268\n",
      "\n",
      "Epoch 2/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.9886  | Val Loss: 2.1153  | IoU: 0.2433  | F1: 0.3909\n",
      "\n",
      "Epoch 3/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.8527  | Val Loss: 1.9976  | IoU: 0.2761  | F1: 0.4322\n",
      "\n",
      "Epoch 4/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.7617  | Val Loss: 2.0210  | IoU: 0.2827  | F1: 0.4401\n",
      "\n",
      "Epoch 5/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.6984  | Val Loss: 1.8558  | IoU: 0.3649  | F1: 0.5336\n"
     ]
    }
   ],
   "source": [
    "transformer_custom = CustomSegmentationTransformer(\n",
    "    img_size=224,\n",
    "    patch_size=32,\n",
    "    in_channels=3,\n",
    "    embed_dim=128,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    num_classes=NUM_CLASSES\n",
    ").to(device)\n",
    "\n",
    "train_and_validate(transformer_custom, train_loader, val_loader, num_epochs=5, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecabfa8",
   "metadata": {},
   "source": [
    "### Оценка качества самостоятельной трансформерной модели\n",
    "\n",
    "Получаем accuracy = 0.5336, что тоже довольно неплохо, но ощутимо ниже готовой модели "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ff43b",
   "metadata": {},
   "source": [
    "### Обучение самостоятельной сверточной модели с использованием гипотез "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da9fbda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 2.6802  | Val Loss: 2.0666  | IoU: 0.2467  | F1: 0.3952\n",
      "\n",
      "Epoch 2/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.8444  | Val Loss: 2.0031  | IoU: 0.2997  | F1: 0.4608\n",
      "\n",
      "Epoch 3/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.6470  | Val Loss: 1.7545  | IoU: 0.3792  | F1: 0.5496\n",
      "\n",
      "Epoch 4/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.7548  | Val Loss: 1.9516  | IoU: 0.3353  | F1: 0.5018\n",
      "\n",
      "Epoch 5/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.7235  | Val Loss: 1.8066  | IoU: 0.3609  | F1: 0.5302\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(unet_custom.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "ce_loss   = nn.CrossEntropyLoss()\n",
    "\n",
    "train_and_validate(unet_custom, train_loader, val_loader, num_epochs=5, learning_rate=1e-3, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9135ad4",
   "metadata": {},
   "source": [
    "### Оценка качества улучшенной самостоятельной сверточной модели\n",
    "\n",
    "Получаем F1 = 0.5302 - примененные гипотезы помогли улучшить бейзлайн"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8897ee3f",
   "metadata": {},
   "source": [
    "### Обучение самостоятельной трансформерной модели с использованием гипотез "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dfda9189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.8159  | Val Loss: 1.9252  | IoU: 0.3284  | F1: 0.4936\n",
      "\n",
      "Epoch 2/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.6770  | Val Loss: 1.7578  | IoU: 0.3748  | F1: 0.5446\n",
      "\n",
      "Epoch 3/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.6087  | Val Loss: 1.7069  | IoU: 0.3791  | F1: 0.5489\n",
      "\n",
      "Epoch 4/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.5697  | Val Loss: 1.6825  | IoU: 0.3864  | F1: 0.5567\n",
      "\n",
      "Epoch 5/5 — LR: 1.00e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss: 1.5374  | Val Loss: 1.6990  | IoU: 0.3695  | F1: 0.5390\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(transformer_custom.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "dice_loss = smp.losses.DiceLoss(mode='multiclass')\n",
    "ce_loss   = nn.CrossEntropyLoss()\n",
    "\n",
    "train_and_validate(transformer_custom, train_loader, val_loader, num_epochs=5, learning_rate=1e-3, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b6b46",
   "metadata": {},
   "source": [
    "### Оценка качества улучшенной самостоятельной трансформеной модели\n",
    "\n",
    "Получаем F1 = 0.5390 - примененные гипотезы помогли немного улучшить бейзлайн"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
