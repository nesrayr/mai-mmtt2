{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47d5b45",
   "metadata": {},
   "source": [
    "# Лабораторная работа №8: Проведение исследований моделями обнаружения и распознавания объектов\n",
    "\n",
    "TACO Dataset YOLO Format\n",
    "Задача -  анализ фото пляжей и улиц для оценки уровня загрязнённости"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3561287d",
   "metadata": {},
   "source": [
    "## 1. Выбор начальных условий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50599e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (1.7.4.2)\n",
      "Requirement already satisfied: bleach in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (3.7)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (6.30.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (75.8.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: webencodings in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "295741c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/vencerlanz09/taco-dataset-yolo-format\n",
      "License(s): other\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d vencerlanz09/taco-dataset-yolo-format -p data --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f3d5bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (8.3.130)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (1.13.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (2.7.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (4.66.2)\n",
      "Requirement already satisfied: psutil in /Users/arsyarullin/Library/Python/3.11/lib/python/site-packages (from ultralytics) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/arsyarullin/Library/Python/3.11/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/arsyarullin/Library/Python/3.11/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/arsyarullin/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33f73c",
   "metadata": {},
   "source": [
    "Для детекции стандартны метрики mAP@0.5 и mAP@0.5:0.95 - их и будем использовать для оценки качества обучения модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5f53da",
   "metadata": {},
   "source": [
    "## 2. Создание бейзлайна и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e2b14",
   "metadata": {},
   "source": [
    "Импортируем YOLO из пакета ultralytics и инициализируем модель 11 версии формата nano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bb61c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "yolo = YOLO('yolo11n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b54b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.130 🚀 Python-3.11.8 torch-2.7.0 CPU (Apple M1 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=0.05, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=taco_yolo_fast8, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/taco_yolo_fast8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    434182  ultralytics.nn.modules.head.Detect           [18, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,593,350 parameters, 2,593,334 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 121.7±37.4 MB/s, size: 36.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/arsyarullin/mai/mult2/lab8/data/train/labels.cache... 210 images, 0 backgrounds, 0 corrupt: 100%|██████████| 210/210 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 88.8±44.3 MB/s, size: 32.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/arsyarullin/mai/mult2/lab8/data/valid/labels.cache... 1704 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1704/1704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/taco_yolo_fast8/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000455, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/taco_yolo_fast8\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5         0G      1.195      2.112      1.028         86        224: 100%|██████████| 7/7 [00:17<00:00,  2.51s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:45<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830      0.327      0.174      0.108     0.0748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5         0G      1.241      2.198      1.031         79        224: 100%|██████████| 7/7 [00:16<00:00,  2.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:45<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830      0.339       0.16      0.109     0.0752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5         0G      1.213      2.036      1.054         72        224: 100%|██████████| 7/7 [00:16<00:00,  2.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:45<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830      0.291      0.157      0.108     0.0741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5         0G      1.162      1.898      1.009         66        224: 100%|██████████| 7/7 [00:16<00:00,  2.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:45<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830      0.274      0.162      0.109     0.0754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5         0G      1.124      1.816      1.016         55        224: 100%|██████████| 7/7 [00:16<00:00,  2.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:46<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830      0.282      0.163       0.11     0.0762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 epochs completed in 0.087 hours.\n",
      "Optimizer stripped from runs/detect/taco_yolo_fast8/weights/last.pt, 5.4MB\n",
      "Optimizer stripped from runs/detect/taco_yolo_fast8/weights/best.pt, 5.4MB\n",
      "\n",
      "Validating runs/detect/taco_yolo_fast8/weights/best.pt...\n",
      "Ultralytics 8.3.130 🚀 Python-3.11.8 torch-2.7.0 CPU (Apple M1 Pro)\n",
      "YOLO11n summary (fused): 100 layers, 2,585,662 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  78%|███████▊  | 21/27 [06:19<00:38,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 5.200s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [22:12<00:00, 49.35s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830      0.275      0.157      0.106     0.0734\n",
      "        Aluminium foil         48         62      0.183     0.0161     0.0335     0.0259\n",
      "            Bottle cap        347        459      0.211       0.49      0.271      0.189\n",
      "                Bottle        275        320      0.405      0.166       0.17      0.115\n",
      "          Broken glass         13        123          0          0          0          0\n",
      "                   Can        187        267      0.264      0.447      0.339      0.234\n",
      "                Carton        207        263      0.223       0.38      0.242      0.182\n",
      "             Cigarette        223        565          1          0    0.00511    0.00275\n",
      "                   Cup        162        186      0.158      0.333       0.18      0.122\n",
      "                   Lid         82         93      0.217     0.0753     0.0992     0.0701\n",
      "          Other litter        148        178      0.094     0.0618     0.0439     0.0281\n",
      "         Other plastic        181        265      0.395     0.0151     0.0357     0.0205\n",
      "                 Paper        126        178     0.0495     0.0225     0.0287     0.0199\n",
      " Plastic bag - wrapper        580        854      0.261      0.396      0.215      0.132\n",
      "     Plastic container         83         90      0.152     0.0818     0.0955     0.0775\n",
      "               Pop tab         87        125          1          0          0          0\n",
      "                 Straw        112        120      0.165      0.117     0.0579     0.0334\n",
      "       Styrofoam piece         77        113     0.0893      0.212     0.0726     0.0634\n",
      "      Unlabeled litter        291        569     0.0895     0.0123     0.0145    0.00626\n",
      "Speed: 0.1ms preprocess, 23.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/taco_yolo_fast8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res_yolo = yolo.train(\n",
    "    data='data/data.yaml',\n",
    "    epochs=5,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    name='taco_yolo',\n",
    "    fraction=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e8beb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f367c701",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c569c45",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70926e9f",
   "metadata": {},
   "source": [
    "## 3. Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3b945",
   "metadata": {},
   "source": [
    "Гипотезы:\n",
    "\n",
    "- Сильнее аугментировать изображения (Mosaic, Copy‑Paste, HSV) - это даст больше синтетики, лучше обобщение;\n",
    "- Будем крутить/масштабировать изображения;\n",
    "- Сменим оптимизатор на AdamW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74011bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.130 🚀 Python-3.11.8 torch-2.7.0 CPU (Apple M1 Pro)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/data.yaml, degrees=5, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=0.1, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=taco_yolo13, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/taco_yolo13, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=2, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    434182  ultralytics.nn.modules.head.Detect           [18, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,593,350 parameters, 2,593,334 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 128.9±26.5 MB/s, size: 35.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/arsyarullin/mai/mult2/lab8/data/train/labels.cache... 420 images, 0 backgrounds, 0 corrupt: 100%|██████████| 420/420 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 157.6±91.0 MB/s, size: 32.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/arsyarullin/mai/mult2/lab8/data/valid/labels.cache... 1704 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1704/1704 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/taco_yolo13/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/taco_yolo13\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G       1.44      4.097      1.154         22        224: 100%|██████████| 14/14 [00:34<00:00,  2.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:45<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830   0.000127     0.0525    0.00134   0.000628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.431      3.459      1.112          4        224: 100%|██████████| 14/14 [00:33<00:00,  2.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:46<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830     0.0027     0.0655    0.00461    0.00253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.447      3.137       1.13         13        224: 100%|██████████| 14/14 [00:33<00:00,  2.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:54<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830    0.00364     0.0964    0.00356    0.00177\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.449      2.987      1.119          8        224: 100%|██████████| 14/14 [01:05<00:00,  4.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:45<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830    0.00843      0.114     0.0103    0.00604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.415      2.819      1.119         18        224: 100%|██████████| 14/14 [00:33<00:00,  2.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:46<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830    0.00901      0.139      0.014    0.00797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.382      2.669      1.087          8        224: 100%|██████████| 14/14 [00:33<00:00,  2.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:45<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830     0.0126      0.166     0.0176     0.0105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       7/10         0G      1.337      2.621      1.102          7        224: 100%|██████████| 14/14 [00:35<00:00,  2.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:46<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830     0.0147      0.178      0.022     0.0134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "       8/10         0G      1.333      2.472      1.079          5        224: 100%|██████████| 14/14 [00:33<00:00,  2.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:46<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830      0.239     0.0537     0.0298     0.0186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G       1.26      2.325      1.049          5        224: 100%|██████████| 14/14 [00:35<00:00,  2.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:46<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830      0.368     0.0388     0.0333     0.0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      1.276      2.329      1.056          8        224: 100%|██████████| 14/14 [00:34<00:00,  2.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:45<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830      0.245     0.0549     0.0356      0.021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.235 hours.\n",
      "Optimizer stripped from runs/detect/taco_yolo13/weights/last.pt, 5.4MB\n",
      "Optimizer stripped from runs/detect/taco_yolo13/weights/best.pt, 5.4MB\n",
      "\n",
      "Validating runs/detect/taco_yolo13/weights/best.pt...\n",
      "Ultralytics 8.3.130 🚀 Python-3.11.8 torch-2.7.0 CPU (Apple M1 Pro)\n",
      "YOLO11n summary (fused): 100 layers, 2,585,662 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:42<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1704       4830      0.245     0.0549     0.0356      0.021\n",
      "        Aluminium foil         48         62          0          0          0          0\n",
      "            Bottle cap        347        459      0.171       0.27      0.114     0.0592\n",
      "                Bottle        275        320      0.472     0.0344     0.0862     0.0572\n",
      "          Broken glass         13        123          1          0          0          0\n",
      "                   Can        187        267      0.156     0.0599     0.0798     0.0455\n",
      "                Carton        207        263      0.163      0.152      0.093     0.0612\n",
      "             Cigarette        223        565          0          0    0.00185    0.00111\n",
      "                   Cup        162        186      0.085     0.0914     0.0493     0.0281\n",
      "                   Lid         82         93          1          0          0          0\n",
      "          Other litter        148        178     0.0604     0.0169     0.0141     0.0074\n",
      "         Other plastic        181        265          1          0     0.0338     0.0222\n",
      "                 Paper        126        178          0          0    0.00925    0.00522\n",
      " Plastic bag - wrapper        580        854      0.185      0.292      0.109     0.0578\n",
      "     Plastic container         83         90          0          0     0.0222     0.0161\n",
      "               Pop tab         87        125          0          0          0          0\n",
      "                 Straw        112        120     0.0361    0.00833     0.0041    0.00208\n",
      "       Styrofoam piece         77        113     0.0378     0.0619     0.0184     0.0131\n",
      "      Unlabeled litter        291        569     0.0366    0.00176    0.00606    0.00234\n",
      "Speed: 0.1ms preprocess, 22.6ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/taco_yolo13\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x16d93bad0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,  7.6626e-05,  3.8313e-05,           0],\n",
       "       [          1,           1,           1, ...,    0.000121,  6.0502e-05,           0],\n",
       "       [          0,           0,           0, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [        0.1,         0.1,         0.1, ...,  1.3309e-05,  6.6547e-06,           0],\n",
       "       [          1,           1,           1, ...,  1.2371e-05,  6.1853e-06,           0],\n",
       "       [    0.14286,     0.14286,     0.06338, ...,  1.4019e-05,  7.0095e-06,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          0,           0,           0, ...,           0,           0,           0],\n",
       "       [   0.022642,    0.022666,    0.046102, ...,    0.013973,   0.0093645,           0],\n",
       "       [    0.07416,     0.07416,     0.11045, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [   0.011182,    0.011184,    0.012646, ...,           0,           0,           0],\n",
       "       [    0.00598,   0.0060044,    0.015192, ...,           0,           0,           0],\n",
       "       [   0.011591,    0.011609,    0.018456, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          0,           0,           0, ...,           0,           0,           0],\n",
       "       [   0.011507,     0.01152,    0.023871, ...,           1,           1,           1],\n",
       "       [   0.042309,    0.042309,    0.071673, ...,           1,           1,           1],\n",
       "       ...,\n",
       "       [  0.0058725,   0.0058738,   0.0069854, ...,           1,           1,           1],\n",
       "       [  0.0030075,   0.0030199,   0.0077469, ...,           1,           1,           1],\n",
       "       [  0.0060549,   0.0060646,    0.010147, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          0,           0,           0, ...,           0,           0,           0],\n",
       "       [    0.69935,     0.69935,     0.67102, ...,   0.0070356,   0.0047043,           0],\n",
       "       [        0.3,         0.3,     0.24063, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [    0.11667,     0.11667,    0.066667, ...,           0,           0,           0],\n",
       "       [    0.51327,     0.51327,     0.38938, ...,           0,           0,           0],\n",
       "       [    0.13533,     0.13533,     0.10193, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.022480072865161953\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([          0,    0.059192,    0.057152,           0,    0.045478,    0.061191,   0.0011089,    0.028098,           0,   0.0073978,    0.022228,   0.0052184,    0.057753,     0.01609,           0,   0.0020757,     0.01306,   0.0023419])\n",
       "names: {0: 'Aluminium foil', 1: 'Bottle cap', 2: 'Bottle', 3: 'Broken glass', 4: 'Can', 5: 'Carton', 6: 'Cigarette', 7: 'Cup', 8: 'Lid', 9: 'Other litter', 10: 'Other plastic', 11: 'Paper', 12: 'Plastic bag - wrapper', 13: 'Plastic container', 14: 'Pop tab', 15: 'Straw', 16: 'Styrofoam piece', 17: 'Unlabeled litter'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.24457131571259952, 'metrics/recall(B)': 0.054911245986811755, 'metrics/mAP50(B)': 0.035608956966304416, 'metrics/mAP50-95(B)': 0.02102130796503501, 'fitness': 0.022480072865161953}\n",
       "save_dir: PosixPath('runs/detect/taco_yolo13')\n",
       "speed: {'preprocess': 0.07592483392676207, 'inference': 22.58323063556674, 'loss': 1.2667254329453542e-05, 'postprocess': 0.24928222593881005}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo = YOLO('yolo11n.pt')\n",
    "\n",
    "yolo.train(\n",
    "    data='data/data.yaml',\n",
    "    epochs=10,\n",
    "    imgsz=224,\n",
    "    batch=32,\n",
    "    name='taco_yolo',\n",
    "    mosaic=1.0,\n",
    "    copy_paste=0.1,\n",
    "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
    "    degrees=5, translate=0.1, scale=0.5, shear=2,\n",
    "    optimizer='AdamW',\n",
    "    lr0=1e-3,\n",
    "    lrf=0.01,\n",
    "    patience=15,\n",
    "    fraction=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4bb385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>1.20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in /Users/arsyarullin/Library/Python/3.11/lib/python/site-packages (from torchmetrics) (24.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchmetrics) (2.7.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchmetrics) (0.14.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.5.1)\n",
      "Requirement already satisfied: typing_extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (2024.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (2.7.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch==2.7.0->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch==2.7.0->torchvision) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from torchvision.ops import nms \n",
    "\n",
    "with open('data/data.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "TRAIN_IMAGES_DIR = config['train']\n",
    "VAL_IMAGES_DIR   = config['val']\n",
    "TRAIN_LABELS_DIR = config.get('train_labels', TRAIN_IMAGES_DIR.replace('images', 'labels'))\n",
    "VAL_LABELS_DIR   = config.get('val_labels',   VAL_IMAGES_DIR.replace('images',   'labels'))\n",
    "CLASS_NAMES      = config['names']\n",
    "NUM_CLASSES      = len(CLASS_NAMES)\n",
    "\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "class YoloDetectionDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        images_dir: str,\n",
    "        labels_dir: str,\n",
    "        image_size: int = 224,\n",
    "        grid_size: int = 7,\n",
    "        num_boxes: int = 1,\n",
    "        num_classes: int = NUM_CLASSES,\n",
    "        transform=None\n",
    "    ):\n",
    "        self.images_dir   = images_dir\n",
    "        self.labels_dir   = labels_dir\n",
    "        self.image_files  = [f for f in os.listdir(images_dir) if f.lower().endswith(('jpg','jpeg','png'))]\n",
    "        self.image_size   = image_size\n",
    "        self.grid_size    = grid_size\n",
    "        self.num_boxes    = num_boxes\n",
    "        self.num_classes  = num_classes\n",
    "        self.transform    = transform or T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_dir, filename)\n",
    "        lbl_path = os.path.join(self.labels_dir, os.path.splitext(filename)[0] + '.txt')\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "\n",
    "        yolo_target = torch.zeros(self.grid_size, self.grid_size, 5*self.num_boxes + self.num_classes)\n",
    "        gt_boxes = []\n",
    "        gt_labels = []\n",
    "\n",
    "        if os.path.exists(lbl_path):\n",
    "            for line in open(lbl_path):\n",
    "                cls, x_center, y_center, w, h = map(float, line.split())\n",
    "                cls = int(cls)\n",
    "\n",
    "                gx = int(x_center * self.grid_size)\n",
    "                gy = int(y_center * self.grid_size)\n",
    "                x_cell = x_center * self.grid_size - gx\n",
    "                y_cell = y_center * self.grid_size - gy\n",
    "\n",
    "                if yolo_target[gy, gx, 4] == 0:\n",
    "                    yolo_target[gy, gx, 0:4] = torch.tensor([x_cell, y_cell, w, h])\n",
    "                    yolo_target[gy, gx, 4] = 1\n",
    "                    yolo_target[gy, gx, 5 + cls] = 1\n",
    "\n",
    "                xc = x_center * self.image_size\n",
    "                yc = y_center * self.image_size\n",
    "                w_abs = w * self.image_size\n",
    "                h_abs = h * self.image_size\n",
    "                x1 = xc - w_abs/2\n",
    "                y1 = yc - h_abs/2\n",
    "                x2 = xc + w_abs/2\n",
    "                y2 = yc + h_abs/2\n",
    "                gt_boxes.append([x1, y1, x2, y2])\n",
    "                gt_labels.append(cls)\n",
    "\n",
    "        boxes_tensor  = torch.tensor(gt_boxes, dtype=torch.float32) if gt_boxes else torch.zeros((0,4), dtype=torch.float32)\n",
    "        labels_tensor = torch.tensor(gt_labels, dtype=torch.int64)    if gt_labels else torch.zeros((0,), dtype=torch.int64)\n",
    "\n",
    "        return image, yolo_target, boxes_tensor, labels_tensor\n",
    "\n",
    "\n",
    "def yolo_collate(batch):\n",
    "    images       = torch.stack([item[0] for item in batch], dim=0)\n",
    "    yolo_targets = torch.stack([item[1] for item in batch], dim=0)\n",
    "    boxes_list   = [item[2] for item in batch]\n",
    "    labels_list  = [item[3] for item in batch]\n",
    "    return images, yolo_targets, boxes_list, labels_list\n",
    "\n",
    "train_dataset = YoloDetectionDataset(\n",
    "    TRAIN_IMAGES_DIR, TRAIN_LABELS_DIR,\n",
    "    image_size=224, grid_size=7, num_boxes=1, num_classes=NUM_CLASSES\n",
    ")\n",
    "val_dataset = YoloDetectionDataset(\n",
    "    VAL_IMAGES_DIR, VAL_LABELS_DIR,\n",
    "    image_size=224, grid_size=7, num_boxes=1, num_classes=NUM_CLASSES\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True,\n",
    "    num_workers=0, pin_memory=False, collate_fn=yolo_collate\n",
    ")\n",
    "val_loader   = DataLoader(\n",
    "    val_dataset,   batch_size=32, shuffle=False,\n",
    "    num_workers=0, pin_memory=False, collate_fn=yolo_collate\n",
    ")\n",
    "\n",
    "class SimpleYOLO(nn.Module):\n",
    "    def __init__(self, grid_size=7, num_boxes=1, num_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.grid_size   = grid_size\n",
    "        self.num_boxes   = num_boxes\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "        backbone = resnet18(weights=weights)\n",
    "        features = list(backbone.children())[:-2]\n",
    "        self.feature_extractor = nn.Sequential(*features)\n",
    "\n",
    "        in_channels = 512  \n",
    "        out_channels = self.num_boxes * 5 + self.num_classes\n",
    "        self.prediction_layer = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        preds    = self.prediction_layer(features)\n",
    "        return preds.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "\n",
    "class YOLOLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        grid_size=7,\n",
    "        num_boxes=1,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        lambda_coord=5,\n",
    "        lambda_noobj=0.5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.grid_size    = grid_size\n",
    "        self.num_boxes    = num_boxes\n",
    "        self.num_classes  = num_classes\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        self.mse = nn.MSELoss(reduction='sum')\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self.ce  = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        obj_mask   = targets[..., 4]\n",
    "        noobj_mask = 1 - obj_mask\n",
    "\n",
    "        pred_box = torch.sigmoid(predictions[..., :4])\n",
    "        pred_obj = predictions[..., 4]\n",
    "        pred_cls = predictions[..., 5:]\n",
    "\n",
    "        tgt_box = targets[..., :4]\n",
    "        tgt_obj = targets[..., 4]\n",
    "        tgt_cls = targets[..., 5:]\n",
    "\n",
    "        coord_loss = self.mse(obj_mask.unsqueeze(-1) * pred_box,\n",
    "                               obj_mask.unsqueeze(-1) * tgt_box)\n",
    "        obj_loss   = torch.sum(obj_mask   * self.bce(pred_obj, tgt_obj))\n",
    "        noobj_loss = torch.sum(noobj_mask * self.bce(pred_obj, tgt_obj))\n",
    "\n",
    "        pred_cls_flat = pred_cls.view(-1, self.num_classes)\n",
    "        tgt_cls_ids   = tgt_cls.argmax(dim=-1).view(-1)\n",
    "        cls_loss_all  = self.ce(pred_cls_flat, tgt_cls_ids)\n",
    "        cls_loss      = torch.sum(obj_mask.view(-1) * cls_loss_all)\n",
    "\n",
    "        return (\n",
    "            self.lambda_coord * coord_loss +\n",
    "            obj_loss +\n",
    "            self.lambda_noobj * noobj_loss +\n",
    "            cls_loss\n",
    "        )\n",
    "\n",
    "def train_one_epoch(\n",
    "    loader: DataLoader,\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    loss_fn: nn.Module,\n",
    "    device: torch.device\n",
    ") -> float:\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for images, yolo_targets, _, _ in loader:\n",
    "        images = images.to(device)\n",
    "        yolo_targets = yolo_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, yolo_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Train Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def evaluate_yolo(\n",
    "    loader: DataLoader,\n",
    "    model: nn.Module,\n",
    "    device: torch.device,\n",
    "    conf_threshold: float = 0.05,\n",
    "    iou_threshold: float = 0.5,\n",
    "    image_size: int = 224\n",
    ") -> None:\n",
    "    model.eval()\n",
    "    metric    = MeanAveragePrecision(iou_thresholds=[0.5])\n",
    "    metric_95 = MeanAveragePrecision()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _, gt_boxes_list, gt_labels_list in loader:\n",
    "            images = images.to(device)\n",
    "            preds  = model(images).cpu()\n",
    "\n",
    "            for b in range(preds.shape[0]):\n",
    "                boxes, scores, labels = [], [], []\n",
    "                for i in range(preds.shape[1]):\n",
    "                    for j in range(preds.shape[2]):\n",
    "                        conf = torch.sigmoid(preds[b,i,j,4]).item()\n",
    "                        if conf < conf_threshold:\n",
    "                            continue\n",
    "                        x_cell, y_cell, w_cell, h_cell = torch.sigmoid(preds[b,i,j,:4])\n",
    "                        x_center = (j + x_cell) / preds.shape[2]\n",
    "                        y_center = (i + y_cell) / preds.shape[1]\n",
    "                        x1 = (x_center - w_cell/2) * image_size\n",
    "                        y1 = (y_center - h_cell/2) * image_size\n",
    "                        x2 = (x_center + w_cell/2) * image_size\n",
    "                        y2 = (y_center + h_cell/2) * image_size\n",
    "                        boxes.append([x1, y1, x2, y2])\n",
    "                        class_prob = torch.softmax(preds[b,i,j,5:], dim=-1)\n",
    "                        cls_score, cls_id = class_prob.max(dim=-1)\n",
    "                        scores.append((conf * cls_score).item())\n",
    "                        labels.append(cls_id.item())\n",
    "\n",
    "                if boxes:\n",
    "                    boxes_t  = torch.tensor(boxes, dtype=torch.float32)\n",
    "                    scores_t = torch.tensor(scores, dtype=torch.float32)\n",
    "                    idxs     = nms(boxes_t, scores_t, iou_threshold)\n",
    "                    boxes_t  = boxes_t[idxs]\n",
    "                    scores_t = scores_t[idxs]\n",
    "                    labels_t = torch.tensor(labels, dtype=torch.int64)[idxs]\n",
    "                else:\n",
    "                    boxes_t  = torch.zeros((0,4))\n",
    "                    scores_t = torch.zeros((0,))\n",
    "                    labels_t = torch.zeros((0,), dtype=torch.int64)\n",
    "\n",
    "                pred = {'boxes': boxes_t, 'scores': scores_t, 'labels': labels_t}\n",
    "                target = {\n",
    "                    'boxes': gt_boxes_list[b],\n",
    "                    'labels': gt_labels_list[b]\n",
    "                }\n",
    "                metric.update([pred], [target])\n",
    "                metric_95.update([pred], [target])\n",
    "\n",
    "    res    = metric.compute()\n",
    "    res_95 = metric_95.compute()\n",
    "    print(f\"mAP@0.50: {res['map_50']:.4f}, mAP@0.50-0.95: {res_95['map']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47bbf217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train Loss: 562.9251\n",
      "mAP@0.50: 0.0060, mAP@0.50-0.95: 0.0012\n",
      "Epoch 2/5\n",
      "Train Loss: 273.9692\n",
      "mAP@0.50: 0.0099, mAP@0.50-0.95: 0.0026\n",
      "Epoch 3/5\n",
      "Train Loss: 175.1563\n",
      "mAP@0.50: 0.0166, mAP@0.50-0.95: 0.0049\n",
      "Epoch 4/5\n",
      "Train Loss: 111.3889\n",
      "mAP@0.50: 0.0206, mAP@0.50-0.95: 0.0066\n",
      "Epoch 5/5\n",
      "Train Loss: 72.3439\n",
      "mAP@0.50: 0.0224, mAP@0.50-0.95: 0.0073\n"
     ]
    }
   ],
   "source": [
    "model        = SimpleYOLO(grid_size=7, num_boxes=1, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "optimizer    = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion    = YOLOLoss(grid_size=7, num_boxes=1, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f\"Epoch {epoch}/{EPOCHS}\")\n",
    "    train_one_epoch(train_loader, model, optimizer, criterion, DEVICE)\n",
    "    evaluate_yolo(val_loader, model, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from torchvision.ops import nms \n",
    "\n",
    "with open('data/data.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "TRAIN_IMAGES_DIR = config['train']\n",
    "VAL_IMAGES_DIR   = config['val']\n",
    "TRAIN_LABELS_DIR = config.get('train_labels', TRAIN_IMAGES_DIR.replace('images', 'labels'))\n",
    "VAL_LABELS_DIR   = config.get('val_labels',   VAL_IMAGES_DIR.replace('images',   'labels'))\n",
    "CLASS_NAMES      = config['names']\n",
    "NUM_CLASSES      = len(CLASS_NAMES)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(degrees=10),\n",
    "    T.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "class YoloDetectionDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        images_dir: str,\n",
    "        labels_dir: str,\n",
    "        image_size: int = 224,\n",
    "        grid_size: int = 7,\n",
    "        num_boxes: int = 1,\n",
    "        num_classes: int = NUM_CLASSES,\n",
    "        transform=None\n",
    "    ):\n",
    "        self.images_dir   = images_dir\n",
    "        self.labels_dir   = labels_dir\n",
    "        self.image_files  = [f for f in os.listdir(images_dir)\n",
    "                             if f.lower().endswith(('jpg','jpeg','png'))]\n",
    "        self.image_size   = image_size\n",
    "        self.grid_size    = grid_size\n",
    "        self.num_boxes    = num_boxes\n",
    "        self.num_classes  = num_classes\n",
    "        self.transform    = transform or T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.image_files[idx]\n",
    "        img_path  = os.path.join(self.images_dir, filename)\n",
    "        lbl_path  = os.path.join(self.labels_dir,\n",
    "                                 os.path.splitext(filename)[0] + '.txt')\n",
    "\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "\n",
    "        yolo_target = torch.zeros(self.grid_size,\n",
    "                                  self.grid_size,\n",
    "                                  5*self.num_boxes + self.num_classes)\n",
    "        gt_boxes, gt_labels = [], []\n",
    "        if os.path.exists(lbl_path):\n",
    "            for line in open(lbl_path):\n",
    "                cls, x_ctr, y_ctr, w, h = map(float, line.split())\n",
    "                cls = int(cls)\n",
    "                gx = int(x_ctr * self.grid_size)\n",
    "                gy = int(y_ctr * self.grid_size)\n",
    "                x_cell = x_ctr * self.grid_size - gx\n",
    "                y_cell = y_ctr * self.grid_size - gy\n",
    "\n",
    "                if yolo_target[gy, gx, 4] == 0:\n",
    "                    yolo_target[gy, gx, 0:4] = torch.tensor([x_cell, y_cell, w, h])\n",
    "                    yolo_target[gy, gx, 4] = 1\n",
    "                    yolo_target[gy, gx, 5 + cls] = 1\n",
    "\n",
    "                # абсолютные координаты\n",
    "                xc = x_ctr * self.image_size\n",
    "                yc = y_ctr * self.image_size\n",
    "                w_abs = w * self.image_size\n",
    "                h_abs = h * self.image_size\n",
    "                x1 = xc - w_abs/2; y1 = yc - h_abs/2\n",
    "                x2 = xc + w_abs/2; y2 = yc + h_abs/2\n",
    "                gt_boxes.append([x1, y1, x2, y2])\n",
    "                gt_labels.append(cls)\n",
    "\n",
    "        boxes_tensor  = (torch.tensor(gt_boxes, dtype=torch.float32)\n",
    "                         if gt_boxes else torch.zeros((0,4)))\n",
    "        labels_tensor = (torch.tensor(gt_labels, dtype=torch.int64)\n",
    "                         if gt_labels else torch.zeros((0,), dtype=torch.int64))\n",
    "\n",
    "        return img, yolo_target, boxes_tensor, labels_tensor\n",
    "\n",
    "\n",
    "def yolo_collate(batch):\n",
    "    images       = torch.stack([b[0] for b in batch], dim=0)\n",
    "    yolo_targets = torch.stack([b[1] for b in batch], dim=0)\n",
    "    boxes_list   = [b[2] for b in batch]\n",
    "    labels_list  = [b[3] for b in batch]\n",
    "    return images, yolo_targets, boxes_list, labels_list\n",
    "\n",
    "train_ds = YoloDetectionDataset(\n",
    "    TRAIN_IMAGES_DIR, TRAIN_LABELS_DIR,\n",
    "    transform=train_transform\n",
    ")\n",
    "val_ds   = YoloDetectionDataset(\n",
    "    VAL_IMAGES_DIR, VAL_LABELS_DIR,\n",
    "    transform=val_transform\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=32, shuffle=True,\n",
    "    num_workers=0, pin_memory=False, collate_fn=yolo_collate\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,   batch_size=32, shuffle=False,\n",
    "    num_workers=0, pin_memory=False, collate_fn=yolo_collate\n",
    ")\n",
    "\n",
    "class SimpleYOLO(nn.Module):\n",
    "    def __init__(self, grid_size=7, num_boxes=1, num_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.grid_size   = grid_size\n",
    "        self.num_boxes   = num_boxes\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "        backbone = resnet18(weights=weights)\n",
    "        features = list(backbone.children())[:-2]\n",
    "        self.feature_extractor = nn.Sequential(*features)\n",
    "\n",
    "        in_ch = 512\n",
    "        out_ch = num_boxes*5 + num_classes\n",
    "        self.pred_layer = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.feature_extractor(x)\n",
    "        p = self.pred_layer(f)\n",
    "        return p.permute(0,2,3,1).contiguous()\n",
    "\n",
    "class YOLOLoss(nn.Module):\n",
    "    def __init__(self, grid_size=7, num_boxes=1, num_classes=NUM_CLASSES,\n",
    "                 lambda_coord=5, lambda_noobj=0.5):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss(reduction='sum')\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self.ce  = nn.CrossEntropyLoss(reduction='none')\n",
    "        self.gc, self.gn = grid_size, num_boxes\n",
    "        self.nc = num_classes\n",
    "        self.lc, self.lno = lambda_coord, lambda_noobj\n",
    "\n",
    "    def forward(self, pred, tgt):\n",
    "        obj_mask   = tgt[...,4]\n",
    "        noobj_mask = 1 - obj_mask\n",
    "        pb = torch.sigmoid(pred[...,:4])\n",
    "        po = pred[...,4]\n",
    "        pc = pred[...,5:]\n",
    "        tb = tgt[..., :4]\n",
    "        to = tgt[..., 4]\n",
    "        tc = tgt[..., 5:]\n",
    "        coord_loss = self.mse(obj_mask.unsqueeze(-1)*pb,\n",
    "                              obj_mask.unsqueeze(-1)*tb)\n",
    "        obj_loss   = torch.sum(obj_mask * self.bce(po, to))\n",
    "        noobj_loss = torch.sum(noobj_mask * self.bce(po, to))\n",
    "        pcl = pc.view(-1, self.nc)\n",
    "        tcls= tc.argmax(-1).view(-1)\n",
    "        cls_all = self.ce(pcl, tcls)\n",
    "        cls_loss= torch.sum(obj_mask.view(-1)*cls_all)\n",
    "        return (self.lc*coord_loss + obj_loss +\n",
    "                self.lno*noobj_loss + cls_loss)\n",
    "\n",
    "def train_one_epoch(loader, model, opt, loss_fn, device):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for imgs, y_targets, *_ in loader:\n",
    "        imgs, y_targets = imgs.to(device), y_targets.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model(imgs)\n",
    "        loss= loss_fn(out, y_targets)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total += loss.item()\n",
    "    print(f\" Train Loss: {total/len(loader):.4f}\")\n",
    "\n",
    "def eval_map(loader, model, device, conf_thresh=0.05, iou_thresh=0.5, img_size=224):\n",
    "    model.eval()\n",
    "    m50    = MeanAveragePrecision(iou_thresholds=[0.5])\n",
    "    m50_95 = MeanAveragePrecision()\n",
    "    with torch.no_grad():\n",
    "        for imgs, _, gt_boxes_list, gt_labels_list in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            preds = model(imgs).cpu()  # [B, G, G, 5+NC]\n",
    "\n",
    "            for b in range(preds.shape[0]):\n",
    "                boxes, scores, labels = [], [], []\n",
    "                G = preds.shape[1]\n",
    "                for i in range(G):\n",
    "                    for j in range(G):\n",
    "                        conf = torch.sigmoid(preds[b,i,j,4]).item()\n",
    "                        if conf < conf_thresh:\n",
    "                            continue\n",
    "                        x_cell, y_cell, w_cell, h_cell = torch.sigmoid(preds[b,i,j,:4])\n",
    "                        x_ctr = (j + x_cell) / G\n",
    "                        y_ctr = (i + y_cell) / G\n",
    "                        x1 = (x_ctr - w_cell/2) * img_size\n",
    "                        y1 = (y_ctr - h_cell/2) * img_size\n",
    "                        x2 = (x_ctr + w_cell/2) * img_size\n",
    "                        y2 = (y_ctr + h_cell/2) * img_size\n",
    "                        boxes.append([x1, y1, x2, y2])\n",
    "\n",
    "                        probs = torch.softmax(preds[b,i,j,5:], dim=-1)\n",
    "                        cls_score, cls_idx = probs.max(dim=-1)\n",
    "                        scores.append((conf * cls_score).item())\n",
    "                        labels.append(cls_idx.item())\n",
    "\n",
    "                # NMS\n",
    "                if boxes:\n",
    "                    boxes_t  = torch.tensor(boxes)\n",
    "                    scores_t = torch.tensor(scores)\n",
    "                    keep     = nms(boxes_t, scores_t, iou_thresh)\n",
    "                    boxes_t  = boxes_t[keep]\n",
    "                    scores_t = scores_t[keep]\n",
    "                    labels_t = torch.tensor(labels)[keep]\n",
    "                else:\n",
    "                    boxes_t  = torch.zeros((0,4))\n",
    "                    scores_t = torch.zeros((0,))\n",
    "                    labels_t = torch.zeros((0,), dtype=torch.int64)\n",
    "\n",
    "                pred = {'boxes': boxes_t, 'scores': scores_t, 'labels': labels_t}\n",
    "                tgt  = {'boxes': gt_boxes_list[b], 'labels': gt_labels_list[b]}\n",
    "                m50.update([pred], [tgt])\n",
    "                m50_95.update([pred], [tgt])\n",
    "\n",
    "    r50    = m50.compute()\n",
    "    r50_95 = m50_95.compute()\n",
    "    print(f\" mAP@0.50: {r50['map_50']:.4f}, mAP@0.50-0.95: {r50_95['map']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7b0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1/5 ===\n",
      " Train Loss: 596.1081\n",
      " mAP@0.50: 0.0013, mAP@0.50-0.95: 0.0002\n",
      "\n",
      "=== Epoch 2/5 ===\n"
     ]
    }
   ],
   "source": [
    "model     = SimpleYOLO().to(DEVICE)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=50, eta_min=1e-6\n",
    ")\n",
    "criterion = YOLOLoss().to(DEVICE)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f\"\\n=== Epoch {epoch}/{EPOCHS} ===\")\n",
    "    train_one_epoch(train_loader, model, optimizer, criterion, DEVICE)\n",
    "    eval_map(val_loader, model, DEVICE)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01be34bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce75de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f732f8b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5f063d9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6593e808",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7739d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(\"data/dataset/train\", transform=train_transform)\n",
    "val_ds = datasets.ImageFolder(\"data/dataset/valid\", transform=train_transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=128,            \n",
    "    shuffle=True,\n",
    "    num_workers=4,           \n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "val_loader   = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds_vit = datasets.ImageFolder(\"data/dataset/train\", transform=vit_transform)\n",
    "val_ds_vit = datasets.ImageFolder(\"data/dataset/valid\", transform=vit_transform)\n",
    "\n",
    "full_len   = len(train_ds_vit)\n",
    "subset_len = full_len // 8\n",
    "rest_len   = full_len - subset_len\n",
    "\n",
    "small_train_ds_vit, _ = random_split(\n",
    "    train_ds_vit,\n",
    "    [subset_len, rest_len],\n",
    "    generator=torch.Generator().manual_seed(42) \n",
    ")\n",
    "\n",
    "train_loader_vit = DataLoader(\n",
    "    small_train_ds_vit,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "val_loader_vit = DataLoader(\n",
    "    val_ds_vit,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6229e8a",
   "metadata": {},
   "source": [
    "Обучим бейзлайн ResNet модель с использованием предложенных гипотез улучшения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec3925fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "model = resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-3\n",
    ")\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a1e29",
   "metadata": {},
   "source": [
    "train_model с возможностью выполнять scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c59c50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, epochs, scheduler=None):\n",
    "    for epoch in range(epochs):\n",
    "        loss_tr, acc_tr = train_one_epoch(model, train_loader, optimizer)\n",
    "        loss_val, acc_val = validate(model, val_loader)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            try:\n",
    "                scheduler.step()\n",
    "            except TypeError:\n",
    "                scheduler.step(loss_val)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}  \"\n",
    "              f\"train loss={loss_tr:.4f} acc={acc_tr:.4f}  \"\n",
    "              f\"val loss={loss_val:.4f} acc={acc_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31395aa",
   "metadata": {},
   "source": [
    "Запуск обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fef7297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5  train loss=3.7277 acc=0.2298  val loss=3.0027 acc=0.2775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5  train loss=1.7500 acc=0.6369  val loss=2.3943 acc=0.4535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5  train loss=0.8736 acc=0.8778  val loss=3.1107 acc=0.2934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5  train loss=0.4236 acc=0.9645  val loss=2.8727 acc=0.3496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5  train loss=0.2401 acc=0.9792  val loss=3.4128 acc=0.2592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, optimizer=optimizer, epochs=5, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5cbd93",
   "metadata": {},
   "source": [
    "Теперь проделаем тот же алгоритм для ViT модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbd852ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5  train loss=3.7133 acc=0.2161  val loss=4.8347 acc=0.1676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5  train loss=1.7677 acc=0.6142  val loss=2.8541 acc=0.3846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5  train loss=0.9537 acc=0.8046  val loss=2.3331 acc=0.4812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5  train loss=0.4789 acc=0.9255  val loss=2.1324 acc=0.5279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5  train loss=0.2317 acc=0.9658  val loss=1.6212 acc=0.6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model_vit = models.vit_b_16(pretrained=True)\n",
    "model_vit.heads.head = nn.Linear(model_vit.heads.head.in_features, num_classes)\n",
    "model_vit.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_vit = optim.SGD(model_vit.parameters(), lr=1e-3, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_vit, step_size=3, gamma=0.5)\n",
    "\n",
    "train(model, train_loader_vit, val_loader_vit, optimizer=optimizer, epochs=5, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1860e3fd",
   "metadata": {},
   "source": [
    "## 4. Имплементация алгоритма машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81389bb",
   "metadata": {},
   "source": [
    "На данном шаге самостоятельно имплементируем сверточную и трансформер модели машинного обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d23c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "IMG_CHANNELS = 3\n",
    "IMAGE_SIZE   = 224\n",
    "PATCH_SIZE   = 16\n",
    "EMBED_DIM    = 256\n",
    "NUM_CLASSES  = len(train_ds.classes)  \n",
    "TRANSFORMER_DEPTH = 6\n",
    "MLP_RATIO    = 4\n",
    "DROPOUT_PROB = 0.1\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(IMG_CHANNELS, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        flat_features = 128 * (IMAGE_SIZE // 8) * (IMAGE_SIZE // 8)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flat_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.backbone(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "class PatchEmbedder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 img_size: int = IMAGE_SIZE,\n",
    "                 patch_size: int = PATCH_SIZE,\n",
    "                 in_channels: int = IMG_CHANNELS,\n",
    "                 embed_dim: int = EMBED_DIM):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels,\n",
    "                              embed_dim,\n",
    "                              kernel_size=patch_size,\n",
    "                              stride=patch_size)\n",
    "        num_patches = (img_size // patch_size) ** 2\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
    "        self.positional_embeddings = nn.Parameter(\n",
    "            torch.randn(1, num_patches + 1, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.proj(x) \\\n",
    "               .flatten(2) \\\n",
    "               .transpose(1, 2)\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        x = torch.cat([cls_tokens, x], dim=1)\n",
    "        return x + self.positional_embeddings\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim: int = EMBED_DIM,\n",
    "                 num_heads: int = 4,\n",
    "                 mlp_ratio: float = MLP_RATIO,\n",
    "                 dropout: float = DROPOUT_PROB):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim,\n",
    "                                               num_heads,\n",
    "                                               dropout=dropout,\n",
    "                                               batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.ffn   = nn.Sequential(\n",
    "            nn.Linear(embed_dim, int(embed_dim * mlp_ratio)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(int(embed_dim * mlp_ratio), embed_dim),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        x = self.norm2(x + self.ffn(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class ViTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_classes: int,\n",
    "                 img_size: int = IMAGE_SIZE,\n",
    "                 patch_size: int = PATCH_SIZE,\n",
    "                 in_channels: int = IMG_CHANNELS,\n",
    "                 embed_dim: int = EMBED_DIM,\n",
    "                 depth: int = TRANSFORMER_DEPTH):\n",
    "        super().__init__()\n",
    "        self.patch_embedder = PatchEmbedder(img_size,\n",
    "                                            patch_size,\n",
    "                                            in_channels,\n",
    "                                            embed_dim)\n",
    "        self.transformer_layers = nn.Sequential(\n",
    "            *[TransformerBlock(embed_dim) for _ in range(depth)]\n",
    "        )\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.patch_embedder(x)\n",
    "        x = self.transformer_layers(x)\n",
    "        cls_token = x[:, 0]              \n",
    "        return self.mlp_head(cls_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eaa37c",
   "metadata": {},
   "source": [
    "Создадим экземпляры классов CNN и ViT моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f423bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.backends.nnpack\n",
    "torch.backends.nnpack.enabled = False\n",
    "\n",
    "cnn = CNNClassifier(num_classes=num_classes).to(device)\n",
    "vit = ViTClassifier(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=1e-3)\n",
    "optimizer_vit = optim.SGD(vit.parameters(), lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ee8fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5  train loss=5.3677 acc=0.0868  val loss=4.0912 acc=0.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5  train loss=3.4358 acc=0.2253  val loss=3.6533 acc=0.2274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5  train loss=2.6100 acc=0.3550  val loss=3.1991 acc=0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5  train loss=2.0243 acc=0.4637  val loss=2.9966 acc=0.3154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5  train loss=1.5573 acc=0.5672  val loss=3.1443 acc=0.3582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485,0.456,0.406],\n",
    "        std=[0.229,0.224,0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(\"data/dataset/train\", transform=transform)\n",
    "val_ds   = datasets.ImageFolder(\"data/dataset/valid\", transform=transform)\n",
    "num_classes = len(train_ds.classes)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=128,            \n",
    "    shuffle=True,\n",
    "    num_workers=4,           \n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "val_loader   = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "train(cnn, train_loader, val_loader, optimizer, epochs=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "528dd28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5  train loss=4.6458 acc=0.0269  val loss=4.4828 acc=0.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5  train loss=4.3483 acc=0.0562  val loss=4.4202 acc=0.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5  train loss=4.2145 acc=0.0611  val loss=4.3275 acc=0.0599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5  train loss=4.0668 acc=0.0842  val loss=4.2022 acc=0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5  train loss=3.9226 acc=0.0879  val loss=4.0944 acc=0.0844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "vit_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485,0.456,0.406],\n",
    "        std=[0.229,0.224,0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "train_ds_vit = datasets.ImageFolder(\"data/dataset/train\", transform=vit_transform)\n",
    "val_ds_vit   = datasets.ImageFolder(\"data/dataset/valid\", transform=vit_transform)\n",
    "num_classes = len(train_ds_vit.classes)\n",
    "\n",
    "ull_len   = len(train_ds_vit)\n",
    "subset_len = full_len // 8\n",
    "rest_len   = full_len - subset_len\n",
    "\n",
    "small_train_ds_vit, _ = random_split(\n",
    "    train_ds_vit,\n",
    "    [subset_len, rest_len],\n",
    "    generator=torch.Generator().manual_seed(42)  \n",
    ")\n",
    "\n",
    "train_loader_vit = DataLoader(\n",
    "    small_train_ds_vit,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "val_loader_vit = DataLoader(\n",
    "    val_ds_vit,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "train(vit, train_loader_vit, val_loader_vit, optimizer_vit, epochs=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51f8ef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5  train loss=6.2549 acc=0.0298  val loss=5.6751 acc=0.0465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5  train loss=4.4938 acc=0.0392  val loss=4.4144 acc=0.0550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5  train loss=4.3131 acc=0.0681  val loss=4.2678 acc=0.0685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5  train loss=4.0447 acc=0.1026  val loss=4.1058 acc=0.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5  train loss=3.8385 acc=0.1239  val loss=3.9352 acc=0.1112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(\"data/dataset/train\", transform=train_transform)\n",
    "val_ds = datasets.ImageFolder(\"data/dataset/valid\", transform=train_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=128,            \n",
    "    shuffle=True,\n",
    "    num_workers=4,           \n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "val_loader   = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, cnn.parameters()),\n",
    "    lr=1e-3\n",
    ")\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(cnn, train_loader, val_loader, optimizer=optimizer, epochs=5, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "785a9c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5  train loss=4.7948 acc=0.0134  val loss=4.8020 acc=0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5  train loss=4.8025 acc=0.0134  val loss=4.8022 acc=0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5  train loss=4.8022 acc=0.0147  val loss=4.8031 acc=0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5  train loss=4.7946 acc=0.0147  val loss=4.8020 acc=0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5  train loss=4.7914 acc=0.0159  val loss=4.8024 acc=0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "vit_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds_vit = datasets.ImageFolder(\"data/dataset/train\", transform=vit_transform)\n",
    "val_ds_vit = datasets.ImageFolder(\"data/dataset/valid\", transform=vit_transform)\n",
    "\n",
    "full_len   = len(train_ds_vit)\n",
    "subset_len = full_len // 8\n",
    "rest_len   = full_len - subset_len\n",
    "\n",
    "small_train_ds_vit, _ = random_split(\n",
    "    train_ds_vit,\n",
    "    [subset_len, rest_len],\n",
    "    generator=torch.Generator().manual_seed(42) \n",
    ")\n",
    "\n",
    "train_loader_vit = DataLoader(\n",
    "    small_train_ds_vit,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "val_loader_vit = DataLoader(\n",
    "    val_ds_vit,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "train(vit, train_loader_vit, val_loader_vit, optimizer=optimizer, epochs=5, scheduler=scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
